{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing any visitor to India will take in â€” probably while staring out the window in awe as their aeroplane descends is the sheer size of this country. It is densely populated and patchworked with distinct neighbourhoods, each with its own culinary identity. It would take several lifetimes to get to know all of the street stands, holes in the wall, neighbourhood favourites, and high-end destinations in this city.\n",
    "And for Indians dining out is and always will be a joyous occasion. Everyone has their own favourite restaurants in the city starting from the street food stall across the street to the 5-star restaurants in the heart of the city. Some are favourites because of the memory attached to it and some are favourites because of the fact that the place has a fantastic ambience. There are a lot of other factors as well which contribute to the likeness of the restaurants which in turn determines their popularity among masses. \n",
    "\n",
    "If you look at this from the business perspective for a restaurant, more popularity may mean more visits to the joint increasing the annual turnover of the restaurants. For any restaurant to survive and do well, the annual turnover of the restaurants has to be substantial. \n",
    "\n",
    "This problem takes a shot at predicting the annual turnover of a set of restaurants across India based on a set of variables given in the data set. This includes the data related to the restaurant such as location, opening date, cuisine type, themes etc. This also includes data pooled from different sources such as social media popularity index, Zomato ratings, etc. Lastly, it also adds a different flavour to the problem by looking at the Customer survey data as well as ratings provided by a mystery visitor data (audit done by a third party). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# to load and manipulate data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# to split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to build decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# to tune different models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# to compute classification metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    silhouette_score\n",
    ")\n",
    "\n",
    "# to scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to perform k-means clustering and compute silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# to perform t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# To ignore unnecessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# to define a common seed value to be used throughout\n",
    "RS=23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv('data/updateme.csv')\n",
    "data = restaurants.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many columns/rows do we have\n",
    "* Checks for null/duplicated data\n",
    "* Check data types and update as necessary\n",
    "* Check summaries and look for immediate oddities\n",
    "  * Negative values where they should always be positive\n",
    "  * Zero values when values should always be higher than zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check both pearson and spearman correlations\n",
    "* Get pairplots\n",
    "* Use the above info to get an idea of most important factors\n",
    "  * Dive deeper into those factors and how they stack up against our target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engingeering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Cluster\n",
    "  * Logistic Regression\n",
    "  * Decision Tree\n",
    "  * Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Selection"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
